{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/blei-lab/edward/blob/master/notebooks/iclr2017.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an interactive version of the [companion webpage](http://edwardlib.org/iclr2017) for the article, Deep Probabilistic Programming [(Tran et al., 2017)](https://arxiv.org/abs/1701.03757). See Edward's [API](http://edwardlib.org/api/) for details on how to interact with data, models, inference, and criticism.\n",
    "\n",
    "The code snippets assume the following versions.\n",
    "```bash\n",
    "pip install edward==1.3.1\n",
    "pip install tensorflow==1.1.0  # alternatively, tensorflow-gpu==1.1.0\n",
    "pip install keras==2.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting edward==1.3.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/bf/e88cae7b8e97884de8a098a8fe98522f007ea8ea3a901dfc191ed41f5eec/edward-1.3.1.tar.gz (49kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 2.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from edward==1.3.1) (1.14.5)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from edward==1.3.1) (1.11.0)\n",
      "Building wheels for collected packages: edward\n",
      "  Running setup.py bdist_wheel for edward ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/88/d9/a8/c6c4d0bebe26d71db3c90533cb8bc8b7e8f94e150e8b1cc647\n",
      "Successfully built edward\n",
      "Installing collected packages: edward\n",
      "  Found existing installation: edward 1.3.5\n",
      "    Uninstalling edward-1.3.5:\n",
      "      Successfully uninstalled edward-1.3.5\n",
      "Successfully installed edward-1.3.1\n",
      "Requirement already satisfied: tensorflow==1.1.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow==1.1.0) (1.14.5)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow==1.1.0) (0.30.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow==1.1.0) (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow==1.1.0) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow==1.1.0) (0.12.2)\n",
      "Requirement already satisfied: setuptools in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from protobuf>=3.2.0->tensorflow==1.1.0) (40.0.0)\n",
      "Collecting keras==2.0.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/bf/98ce2f2ab1364f6e83c0ffc5216fff3058fd990d8a3b957ebad3a6cedeeb/Keras-2.0.0.tar.gz (191kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 4.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorflow in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras==2.0.0) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras==2.0.0) (3.12)\n",
      "Requirement already satisfied: six in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from keras==2.0.0) (1.11.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow->keras==2.0.0) (0.30.0)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow->keras==2.0.0) (1.14.5)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow->keras==2.0.0) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from tensorflow->keras==2.0.0) (0.12.2)\n",
      "Requirement already satisfied: setuptools in /home/nbuser/anaconda3_501/lib/python3.6/site-packages (from protobuf>=3.2.0->tensorflow->keras==2.0.0) (40.0.0)\n",
      "Building wheels for collected packages: keras\n",
      "  Running setup.py bdist_wheel for keras ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/b0/a1/f4/f5f6a53dd71728cae0176b860f8c4304dd5d3fc2b8387ef59c\n",
      "Successfully built keras\n",
      "\u001b[31mkeras-preprocessing 1.0.1 has requirement keras>=2.1.6, but you'll have keras 2.0.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mkeras-applications 1.0.2 has requirement keras>=2.1.6, but you'll have keras 2.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: keras\n",
      "  Found existing installation: Keras 2.2.0\n",
      "    Uninstalling Keras-2.2.0:\n",
      "      Successfully uninstalled Keras-2.2.0\n",
      "Successfully installed keras-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install edward==1.3.1\n",
    "!pip install tensorflow==1.1.0  # alternatively, tensorflow-gpu==1.1.0\n",
    "!pip install keras==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3. Compositional Representations for Probabilistic Models\n",
    "\n",
    "__Figure 1__. Beta-Bernoulli program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edward.models import Bernoulli, Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = Beta(1.0, 1.0)\n",
    "x = Bernoulli(tf.ones(50) * theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of it in use, see\n",
    "[`examples/beta_bernoulli.py`](https://github.com/blei-lab/edward/blob/master/examples/beta_bernoulli.py)\n",
    "in the Github repository.\n",
    "\n",
    "__Figure 2__. Variational auto-encoder for a data set of 28 x 28 pixel images\n",
    "(Kingma & Welling, 2014; Rezende, Mohamed, & Wierstra, 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from edward.models import Bernoulli, Normal\n",
    "from keras.layers import Dense\n",
    "\n",
    "N = 55000  # number of data points\n",
    "d = 50  # latent dimension\n",
    "\n",
    "# Probabilistic model\n",
    "z = Normal(loc=tf.zeros([N, d]), scale=tf.ones([N, d]))\n",
    "h = Dense(256, activation='relu')(z)\n",
    "x = Bernoulli(logits=Dense(28 * 28, activation=None)(h))\n",
    "\n",
    "# Variational model\n",
    "qx = tf.placeholder(tf.float32, [N, 28 * 28])\n",
    "qh = Dense(256, activation='relu')(qx)\n",
    "qz = Normal(loc=Dense(d, activation=None)(qh),\n",
    "            scale=Dense(d, activation='softplus')(qh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of it in use, see\n",
    "[`examples/vae.py`](https://github.com/blei-lab/edward/blob/master/examples/vae.py)\n",
    "in the Github repository.\n",
    "\n",
    "__Figure 3__. Bayesian recurrent neural network (Radford M Neal, 2012).\n",
    "The program has an unspecified number of time steps; it uses a\n",
    "symbolic for loop (`tf.scan`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import tensorflow as tf\n",
    "from edward.models import Normal\n",
    "\n",
    "H = 50  # number of hidden units\n",
    "D = 10  # number of features\n",
    "\n",
    "def rnn_cell(hprev, xt):\n",
    "  return tf.tanh(ed.dot(hprev, Wh) + ed.dot(xt, Wx) + bh)\n",
    "\n",
    "Wh = Normal(loc=tf.zeros([H, H]), scale=tf.ones([H, H]))\n",
    "Wx = Normal(loc=tf.zeros([D, H]), scale=tf.ones([D, H]))\n",
    "Wy = Normal(loc=tf.zeros([H, 1]), scale=tf.ones([H, 1]))\n",
    "bh = Normal(loc=tf.zeros(H), scale=tf.ones(H))\n",
    "by = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, D])\n",
    "h = tf.scan(rnn_cell, x, initializer=tf.zeros(H))\n",
    "y = Normal(loc=tf.matmul(h, Wy) + by, scale=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4. Compositional Representations for Inference\n",
    "\n",
    "__Figure 5__. Hierarchical model (Gelman & Hill, 2006).\n",
    "  It is a mixture of Gaussians over\n",
    "  $D$-dimensional data $\\{x_n\\}\\in\\mathbb{R}^{N\\times D}$. There are\n",
    "  $K$ latent cluster means $\\beta\\in\\mathbb{R}^{K\\times D}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from edward.models import Categorical, Normal\n",
    "\n",
    "N = 10000  # number of data points\n",
    "D = 2  # data dimension\n",
    "K = 5  # number of clusters\n",
    "\n",
    "beta = Normal(loc=tf.zeros([K, D]), scale=tf.ones([K, D]))\n",
    "z = Categorical(logits=tf.zeros([N, K]))\n",
    "x = Normal(loc=tf.gather(beta, z), scale=tf.ones([N, D]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is used below in Figure 6 (left/right) and Figure * (variational EM).\n",
    "\n",
    "__Figure 6__ __(left)__. Variational inference\n",
    "(Jordan, Ghahramani, Jaakkola, & Saul, 1999).\n",
    "It performs inference on the model defined in Figure 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class VariationalInference with abstract methods build_loss_and_gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d66f6a586c39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mqz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0minference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariationalInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqz\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class VariationalInference with abstract methods build_loss_and_gradients"
     ]
    }
   ],
   "source": [
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from edward.models import Categorical, Normal\n",
    "\n",
    "x_train = np.zeros([N, D])\n",
    "\n",
    "qbeta = Normal(loc=tf.Variable(tf.zeros([K, D])),\n",
    "               scale=tf.exp(tf.Variable(tf.zeros([K, D]))))\n",
    "qz = Categorical(logits=tf.Variable(tf.zeros([N, K])))\n",
    "\n",
    "inference = ed.VariationalInference({beta: qbeta, z: qz}, data={x: x_train})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 6__ __(right)__. Monte Carlo (Robert & Casella, 1999).\n",
    "It performs inference on the model defined in Figure 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from edward.models import Empirical\n",
    "\n",
    "x_train = np.zeros([N, D])\n",
    "\n",
    "T = 10000  # number of samples\n",
    "qbeta = Empirical(params=tf.Variable(tf.zeros([T, K, D])))\n",
    "qz = Empirical(params=tf.Variable(tf.zeros([T, N])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 7__. Generative adversarial network\n",
    "(Goodfellow et al., 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nbuser/anaconda3_501/lib/python3.6/site-packages/edward/util/random_variables.py:48: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if not key.shape.is_compatible_with(np.shape(value)):\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[55000,784]\n\t [[Node: data/Variable/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@data/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](data/Variable, _recv_data/Placeholder_0)]]\n\nCaused by op 'data/Variable/Assign', defined at:\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-578cfa528ac0>\", line 27, in <module>\n    discriminator=discriminative_network)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/edward/inferences/gan_inference.py\", line 58, in __init__\n    super(GANInference, self).__init__(None, data)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/edward/inferences/variational_inference.py\", line 32, in __init__\n    super(VariationalInference, self).__init__(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/edward/inferences/inference.py\", line 81, in __init__\n    var = tf.Variable(ph, trainable=False, collections=[])\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 306, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[55000,784]\n\t [[Node: data/Variable/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@data/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](data/Variable, _recv_data/Placeholder_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[55000,784]\n\t [[Node: data/Variable/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@data/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](data/Variable, _recv_data/Placeholder_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-578cfa528ac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# INFERENCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m inference = ed.GANInference(data={x: x_train},\n\u001b[0;32m---> 27\u001b[0;31m                             discriminator=discriminative_network)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/edward/inferences/gan_inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, discriminator)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGANInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m   def initialize(self, optimizer=None, optimizer_d=None,\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/edward/inferences/variational_inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m   \"\"\"\n\u001b[1;32m     31\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariationalInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   def initialize(self, optimizer=None, var_list=None, use_prettytensor=False,\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/edward/inferences/inference.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, latent_vars, data)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[55000,784]\n\t [[Node: data/Variable/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@data/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](data/Variable, _recv_data/Placeholder_0)]]\n\nCaused by op 'data/Variable/Assign', defined at:\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-578cfa528ac0>\", line 27, in <module>\n    discriminator=discriminative_network)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/edward/inferences/gan_inference.py\", line 58, in __init__\n    super(GANInference, self).__init__(None, data)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/edward/inferences/variational_inference.py\", line 32, in __init__\n    super(VariationalInference, self).__init__(*args, **kwargs)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/edward/inferences/inference.py\", line 81, in __init__\n    var = tf.Variable(ph, trainable=False, collections=[])\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 197, in __init__\n    expected_shape=expected_shape)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 306, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/nbuser/anaconda3_501/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[55000,784]\n\t [[Node: data/Variable/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@data/Variable\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](data/Variable, _recv_data/Placeholder_0)]]\n"
     ]
    }
   ],
   "source": [
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from edward.models import Normal\n",
    "from keras.layers import Dense\n",
    "\n",
    "N = 55000  # number of data points\n",
    "d = 50  # latent dimension\n",
    "\n",
    "def generative_network(eps):\n",
    "  h = Dense(256, activation='relu')(eps)\n",
    "  return Dense(28 * 28, activation=None)(h)\n",
    "\n",
    "def discriminative_network(x):\n",
    "  h = Dense(28 * 28, activation='relu')(x)\n",
    "  return Dense(1, activation=None)(h)\n",
    "\n",
    "# DATA\n",
    "x_train = np.zeros([N, 28 * 28])\n",
    "\n",
    "# MODEL\n",
    "eps = Normal(loc=tf.zeros([N, d]), scale=tf.ones([N, d]))\n",
    "x = generative_network(eps)\n",
    "\n",
    "# INFERENCE\n",
    "inference = ed.GANInference(data={x: x_train},\n",
    "                            discriminator=discriminative_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of it in use, see the\n",
    "[generative adversarial networks](http://edwardlib.org/tutorials/gan) tutorial.\n",
    "\n",
    "__Figure *__. Variational EM (Radford M. Neal & Hinton, 1993).\n",
    "It performs inference on the model defined in Figure 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class VariationalInference with abstract methods build_loss_and_gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a900da3e67a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mqz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0minference_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariationalInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqz\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqbeta\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0minference_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqbeta\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqz\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class VariationalInference with abstract methods build_loss_and_gradients"
     ]
    }
   ],
   "source": [
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from edward.models import Categorical, PointMass\n",
    "\n",
    "# DATA\n",
    "x_train = np.zeros([N, D])\n",
    "\n",
    "# INFERENCE\n",
    "qbeta = PointMass(params=tf.Variable(tf.zeros([K, D])))\n",
    "qz = Categorical(logits=tf.Variable(tf.zeros([N, K])))\n",
    "\n",
    "inference_e = ed.VariationalInference({z: qz}, data={x: x_train, beta: qbeta})\n",
    "inference_m = ed.MAP({beta: qbeta}, data={x: x_train, z: qz})\n",
    "\n",
    "inference_e.initialize()\n",
    "inference_m.initialize()\n",
    "\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "for _ in range(10000):\n",
    "  inference_e.update()\n",
    "  inference_m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, see the\n",
    "[inference compositionality](http://edwardlib.org/api/inference-compositionality) webpage.\n",
    "See\n",
    "[`examples/factor_analysis.py`](https://github.com/blei-lab/edward/blob/master/examples/factor_analysis.py) for\n",
    "a version performing Monte Carlo EM for logistic factor analysis\n",
    "in the Github repository.\n",
    "It leverages Hamiltonian Monte Carlo for the E-step to perform maximum\n",
    "marginal a posteriori.\n",
    "\n",
    "__Figure *__. Data subsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class VariationalInference with abstract methods build_loss_and_gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-9536e8b5775b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mqz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0minference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariationalInference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mqz\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class VariationalInference with abstract methods build_loss_and_gradients"
     ]
    }
   ],
   "source": [
    "import edward as ed\n",
    "import tensorflow as tf\n",
    "from edward.models import Categorical, Normal\n",
    "\n",
    "N = 10000  # number of data points\n",
    "M = 128  # batch size during training\n",
    "D = 2  # data dimension\n",
    "K = 5  # number of clusters\n",
    "\n",
    "# DATA\n",
    "x_batch = tf.placeholder(tf.float32, [M, D])\n",
    "\n",
    "# MODEL\n",
    "beta = Normal(loc=tf.zeros([K, D]), scale=tf.ones([K, D]))\n",
    "z = Categorical(logits=tf.zeros([M, K]))\n",
    "x = Normal(loc=tf.gather(beta, z), scale=tf.ones([M, D]))\n",
    "\n",
    "# INFERENCE\n",
    "qbeta = Normal(loc=tf.Variable(tf.zeros([K, D])),\n",
    "               scale=tf.nn.softplus(tf.Variable(tf.zeros([K, D]))))\n",
    "qz = Categorical(logits=tf.Variable(tf.zeros([M, D])))\n",
    "\n",
    "inference = ed.VariationalInference({beta: qbeta, z: qz}, data={x: x_batch})\n",
    "inference.initialize(scale={x: float(N) / M, z: float(N) / M})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, see the\n",
    "[data subsampling](http://edwardlib.org/api/inference-data-subsampling) webpage.\n",
    "\n",
    "## Section 5. Experiments\n",
    "\n",
    "__Figure 9__. Bayesian logistic regression with Hamiltonian Monte Carlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import edward as ed\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from edward.models import Bernoulli, Empirical, Normal\n",
    "\n",
    "N = 581012  # number of data points\n",
    "D = 54  # number of features\n",
    "T = 100  # number of empirical samples\n",
    "\n",
    "# DATA\n",
    "x_data = np.zeros([N, D])\n",
    "y_data = np.zeros([N])\n",
    "\n",
    "# MODEL\n",
    "x = tf.Variable(x_data, trainable=False)\n",
    "beta = Normal(loc=tf.zeros(D), scale=tf.ones(D))\n",
    "y = Bernoulli(logits=ed.dot(x, beta))\n",
    "\n",
    "# INFERENCE\n",
    "qbeta = Empirical(params=tf.Variable(tf.zeros([T, D])))\n",
    "inference = ed.HMC({beta: qbeta}, data={y: y_data})\n",
    "inference.run(step_size=0.5 / N, n_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of it in use, see\n",
    "[`examples/bayesian_logistic_regression.py`](https://github.com/blei-lab/edward/blob/master/examples/bayesian_logistic_regression.py)\n",
    "in the Github repository.\n",
    "\n",
    "## Appendix A. Model Examples\n",
    "\n",
    "__Figure 10__. Bayesian neural network for classification (Denker, Schwartz, Wittner, & Solla, 1987)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from edward.models import Bernoulli, Normal\n",
    "\n",
    "N = 1000  # number of data points\n",
    "D = 528  # number of features\n",
    "H = 256  # hidden layer size\n",
    "\n",
    "W_0 = Normal(loc=tf.zeros([D, H]), scale=tf.ones([D, H]))\n",
    "W_1 = Normal(loc=tf.zeros([H, 1]), scale=tf.ones([H, 1]))\n",
    "b_0 = Normal(loc=tf.zeros(H), scale=tf.ones(H))\n",
    "b_1 = Normal(loc=tf.zeros(1), scale=tf.ones(1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, [N, D])\n",
    "y = Bernoulli(logits=tf.matmul(tf.nn.tanh(tf.matmul(x, W_0) + b_0), W_1) + b_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of it in use, see\n",
    "[`examples/getting_started_example.py`](https://github.com/blei-lab/edward/blob/master/examples/getting_started_example.py)\n",
    "in the Github repository.\n",
    "\n",
    "__Figure 11__. Latent Dirichlet allocation (D. M. Blei, Ng, & Jordan, 2003)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-0e4cf596901c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirichlet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirichlet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'list'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from edward.models import Categorical, Dirichlet\n",
    "\n",
    "D = 4  # number of documents\n",
    "N = [11502, 213, 1523, 1351]  # words per doc\n",
    "K = 10  # number of topics\n",
    "V = 100000  # vocabulary size\n",
    "\n",
    "theta = Dirichlet(tf.zeros([D, K]) + 0.1)\n",
    "phi = Dirichlet(tf.zeros([K, V]) + 0.05)\n",
    "z = [[0] * N] * D\n",
    "w = [[0] * N] * D\n",
    "for d in range(D):\n",
    "  for n in range(N[d]):\n",
    "    z[d][n] = Categorical(theta[d, :])\n",
    "    w[d][n] = Categorical(phi[z[d][n], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 12__. Gaussian matrix factorization\n",
    "(Salakhutdinov & Mnih, 2011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from edward.models import Normal\n",
    "\n",
    "N = 10\n",
    "M = 10\n",
    "K = 5  # latent dimension\n",
    "\n",
    "U = Normal(loc=tf.zeros([M, K]), scale=tf.ones([M, K]))\n",
    "V = Normal(loc=tf.zeros([N, K]), scale=tf.ones([N, K]))\n",
    "Y = Normal(loc=tf.matmul(U, V, transpose_b=True), scale=tf.ones([N, M]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 13__. Dirichlet process mixture model (Antoniak, 1974)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from edward.models import DirichletProcess, Normal\n",
    "\n",
    "N = 1000  # number of data points\n",
    "D = 5  # data dimensionality\n",
    "\n",
    "dp = DirichletProcess(alpha=1.0, base=Normal(loc=tf.zeros(D), scale=tf.ones(D)))\n",
    "mu = dp.sample(N)\n",
    "x = Normal(loc=loc, scale=tf.ones([N, D]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the essential component defining the `DirichletProcess`, see\n",
    "[`examples/pp_dirichlet_process.py`](https://github.com/blei-lab/edward/blob/master/examples/pp_dirichlet_process.py)\n",
    "in the Github repository. Its source implementation can be found at\n",
    "[`edward/models/dirichlet_process.py`](https://github.com/blei-lab/edward/blob/master/edward/models/dirichlet_process.py).\n",
    "\n",
    "## Appendix B. Inference Examples\n",
    "\n",
    "__Figure *__. Stochastic variational inference (M. D. Hoffman, Blei, Wang, & Paisley, 2013). \n",
    "For more details, see the\n",
    "[data subsampling](http://edwardlib.org/api/inference-data-subsampling) webpage.\n",
    "\n",
    "## Appendix C. Complete Examples\n",
    "\n",
    "__Figure 15__. Variational auto-encoder\n",
    "(Kingma & Welling, 2014; Rezende et al., 2014).\n",
    "See the script\n",
    "\\href{https://github.com/blei-lab/edward/blob/master/examples/vae.py}{\\texttt{examples/vae.py}}\n",
    "in the Github repository.\n",
    "\n",
    "__Figure 16__. Exponential family embedding (Rudolph, Ruiz, Mandt, & Blei, 2016).\n",
    "A Github repository with comprehensive features is available at\n",
    "[mariru/exponential_family_embeddings](https://github.com/mariru/exponential_family_embeddings)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
